{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the variables used in the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_training = pd.read_csv('data\\raw_data\\PAN_15_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>02ae95de-7ee3-453a-978d-25d28b3f1a88</td>\n",
       "      <td>Things I want for my business cards but are to...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02ae95de-7ee3-453a-978d-25d28b3f1a88</td>\n",
       "      <td>\"painters produced their most highly valued wo...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>02ae95de-7ee3-453a-978d-25d28b3f1a88</td>\n",
       "      <td>@username your new discussion layout is confus...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02ae95de-7ee3-453a-978d-25d28b3f1a88</td>\n",
       "      <td>I never really understood why game environment...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>02ae95de-7ee3-453a-978d-25d28b3f1a88</td>\n",
       "      <td>@username 20k and 2048² on a gun, fine. But th...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>14161</td>\n",
       "      <td>fde8eb00-0444-4159-9b65-1ead60c2dc88</td>\n",
       "      <td>Fifty Writing Tools: Quick List | Poynter. htt...</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>14162</td>\n",
       "      <td>fde8eb00-0444-4159-9b65-1ead60c2dc88</td>\n",
       "      <td>Video: How To Make Vietnamese Coffee (by HighB...</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>14163</td>\n",
       "      <td>fde8eb00-0444-4159-9b65-1ead60c2dc88</td>\n",
       "      <td>lyx is soooo awesome!!! finally figured out ho...</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14164</th>\n",
       "      <td>14164</td>\n",
       "      <td>fde8eb00-0444-4159-9b65-1ead60c2dc88</td>\n",
       "      <td>Impact Algorithms: Strategies Remarkable Peopl...</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>14165</td>\n",
       "      <td>fde8eb00-0444-4159-9b65-1ead60c2dc88</td>\n",
       "      <td>Why You're Tired - Causes of Fatigue http://tu...</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14166 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                author  \\\n",
       "0               0  02ae95de-7ee3-453a-978d-25d28b3f1a88   \n",
       "1               1  02ae95de-7ee3-453a-978d-25d28b3f1a88   \n",
       "2               2  02ae95de-7ee3-453a-978d-25d28b3f1a88   \n",
       "3               3  02ae95de-7ee3-453a-978d-25d28b3f1a88   \n",
       "4               4  02ae95de-7ee3-453a-978d-25d28b3f1a88   \n",
       "...           ...                                   ...   \n",
       "14161       14161  fde8eb00-0444-4159-9b65-1ead60c2dc88   \n",
       "14162       14162  fde8eb00-0444-4159-9b65-1ead60c2dc88   \n",
       "14163       14163  fde8eb00-0444-4159-9b65-1ead60c2dc88   \n",
       "14164       14164  fde8eb00-0444-4159-9b65-1ead60c2dc88   \n",
       "14165       14165  fde8eb00-0444-4159-9b65-1ead60c2dc88   \n",
       "\n",
       "                                                    text gender    age  \n",
       "0      Things I want for my business cards but are to...      M  25-34  \n",
       "1      \"painters produced their most highly valued wo...      M  25-34  \n",
       "2      @username your new discussion layout is confus...      M  25-34  \n",
       "3      I never really understood why game environment...      M  25-34  \n",
       "4      @username 20k and 2048² on a gun, fine. But th...      M  25-34  \n",
       "...                                                  ...    ...    ...  \n",
       "14161  Fifty Writing Tools: Quick List | Poynter. htt...      F  25-34  \n",
       "14162  Video: How To Make Vietnamese Coffee (by HighB...      F  25-34  \n",
       "14163  lyx is soooo awesome!!! finally figured out ho...      F  25-34  \n",
       "14164  Impact Algorithms: Strategies Remarkable Peopl...      F  25-34  \n",
       "14165  Why You're Tired - Causes of Fatigue http://tu...      F  25-34  \n",
       "\n",
       "[14166 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pan15_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "\n",
    "\n",
    "# Character-based features\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def alphabetic_ratio(text):\n",
    "    alphabetic = sum(c.isalpha() for c in text)\n",
    "    return alphabetic/len(text)\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    upper = sum(c.isupper() for c in text)\n",
    "    return upper/len(text)\n",
    "\n",
    "def digit_ratio(text):\n",
    "    digit = sum(c.isdigit() for c in text)\n",
    "    return digit/len(text)\n",
    "\n",
    "def whitespace_ratio(text):\n",
    "    whitespace = sum(c.isspace() for c in text)\n",
    "    return whitespace/len(text)\n",
    "\n",
    "def tab_ratio(text):\n",
    "    tabs = text.count('\\t')\n",
    "    return tabs/len(text)\n",
    "\n",
    "def letter_ratio(text, letter):\n",
    "    text = text.lower()\n",
    "    letter_count = text.count(letter)\n",
    "    return letter_count/len(text)\n",
    "\n",
    "def specialcharacter_ratio(text, character):\n",
    "    spec_count = text.count(character)\n",
    "    return spec_count/len(text)\n",
    "\n",
    "# Word-based features\n",
    "def number_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return len(words)\n",
    "\n",
    "def word_length(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length/num_words\n",
    "\n",
    "def vocabulary_richness(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_uniq_words = len(set(words))\n",
    "    return num_uniq_words/num_words\n",
    "\n",
    "def long_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    long_words_list = [word for word in words if len(word) > 6]\n",
    "    return len(long_words_list)/len(words)\n",
    "\n",
    "def short_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    short_words_list = [word for word in words if 1 <= len(word) <= 3]\n",
    "    return len(short_words_list)/len(words)\n",
    "\n",
    "def legomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    return len(legomena)/len(words)\n",
    "\n",
    "def dislegomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    return len(dislegomena)/len(words)\n",
    "\n",
    "def yules_k(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    Vi = FreqDist(freq.values())\n",
    "    K = 10**4 * ((-N + sum(i**2 * Vi[i] for i in Vi))/N**2)\n",
    "    return K\n",
    "\n",
    "def simpson_d(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    if N < 2:\n",
    "        return 0\n",
    "    D = sum(fr * (fr - 1) / (N * (N - 1)) for fr in freq.values())\n",
    "    return D\n",
    "\n",
    "def sichel_s(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    S = len(dislegomena)/len(freq.values())\n",
    "    return S\n",
    "\n",
    "def honores_r(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    V = len(freq.values())\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    R = (100*np.log(N)/(1-(len(legomena)/V)))\n",
    "    return R\n",
    "\n",
    "def entropy(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    E = -sum((fr / N) * np.log(fr/N) for fr in freq.values())\n",
    "    return E\n",
    "\n",
    "# Syntatic features\n",
    "def punctuations_ratio(text, punctuation):\n",
    "    punctuation_list = re.findall(punctuation, text)\n",
    "    return len(punctuation_list)/len(text)\n",
    "\n",
    "# Structural features\n",
    "def lines(text):\n",
    "    return len(text.split('\\n'))\n",
    "\n",
    "def sentences(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "def paragraphs(text):\n",
    "    return len([par for par in text.split('\\n\\n') if par.strip()])\n",
    "\n",
    "def sentence_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(sent_tokenize(par)) for par in pars])\n",
    "\n",
    "def words_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(re.findall(r'\\b\\w+\\b', par)) for par in pars])\n",
    "\n",
    "def chars_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(par) for par in pars])\n",
    "\n",
    "def words_sentences(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return statistics.mean([len(word_tokenize(sentence)) for sentence in sents])\n",
    "\n",
    "def uppercase_start(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return (sum(1 for sentence in sents if sentence[0].isupper()) / len(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataframe, text_column):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Character-based features\n",
    "    features['total_characters'] = dataframe[text_column].apply(character_count)\n",
    "    features['ratio_alphabetic'] = dataframe[text_column].apply(alphabetic_ratio)\n",
    "    features['ratio_uppercase'] = dataframe[text_column].apply(uppercase_ratio)\n",
    "    features['ratio_digit'] = dataframe[text_column].apply(digit_ratio)\n",
    "    features['ratio_whitespace'] = dataframe[text_column].apply(whitespace_ratio)\n",
    "    features['ratio_tabspace'] = dataframe[text_column].apply(tab_ratio)\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    for letter in letters:\n",
    "        features[letter+'_frequency'] = dataframe[text_column].apply(letter_ratio, args=(letter,))\n",
    "    special_characters = ['~', '@', '#', '$', '%', '^', '&', '*', '-', '_', '=', '+', '>', '<', '[', ']', '{', '}', '/', '\\\\', '|']\n",
    "    for character in special_characters:\n",
    "        features[character+'_frequency'] = dataframe[text_column].apply(specialcharacter_ratio, args=(character,))\n",
    "    \n",
    "    # Word-based features\n",
    "    features['total_words'] = dataframe[text_column].apply(number_words)\n",
    "    features['word_length'] = dataframe[text_column].apply(word_length)\n",
    "    features['vocabulary_richness'] = dataframe[text_column].apply(vocabulary_richness)\n",
    "    features['long_words'] = dataframe[text_column].apply(long_words)\n",
    "    features['short_words'] = dataframe[text_column].apply(short_words)\n",
    "    features['hapax_legomena'] = dataframe[text_column].apply(legomena)\n",
    "    features['hapax_dislegomena'] = dataframe[text_column].apply(dislegomena)\n",
    "    features['yules_k'] = dataframe[text_column].apply(yules_k)\n",
    "    features['simpson_d'] = dataframe[text_column].apply(simpson_d)\n",
    "    features['sichel_s'] = dataframe[text_column].apply(sichel_s)\n",
    "    features['honore_r'] = dataframe[text_column].apply(honores_r)\n",
    "    features['entropy'] =  dataframe[text_column].apply(entropy)\n",
    "    # Brunet W?\n",
    "    # word length frequency distribution\n",
    "\n",
    "    \n",
    "    # Syntactic features\n",
    "    punctuations = [r\"’\", r\",\", r\"\\.\", r\":\", r\";\", r\"\\?\", r\"\\?{2,}\", r\"!\", r\"!{2,}\", r\"\\.{3}\"]\n",
    "    for punctuation in punctuations:\n",
    "        features[punctuation+\"_frequency\"] = dataframe[text_column].apply(punctuations_ratio, args=(punctuation,))\n",
    "\n",
    "    # Structural features\n",
    "    features['number_lines'] = dataframe[text_column].apply(lines)\n",
    "    features['number_sentences'] = dataframe[text_column].apply(sentences)\n",
    "    features['number_paragraphs'] = dataframe[text_column].apply(paragraphs)\n",
    "    features['sentences_per_paragraph'] = dataframe[text_column].apply(sentence_paragraph)\n",
    "    features['word_per_paragraph'] = dataframe[text_column].apply(words_paragraph)\n",
    "    features['character_per_paragraph'] = dataframe[text_column].apply(chars_paragraph)\n",
    "    features['word_per_sentence'] = dataframe[text_column].apply(words_sentences)\n",
    "    features['ratio_sentencestart_uppercase'] = dataframe[text_column].apply(uppercase_start)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_characters</th>\n",
       "      <th>ratio_alphabetic</th>\n",
       "      <th>ratio_uppercase</th>\n",
       "      <th>ratio_digit</th>\n",
       "      <th>ratio_whitespace</th>\n",
       "      <th>ratio_tabspace</th>\n",
       "      <th>a_frequency</th>\n",
       "      <th>b_frequency</th>\n",
       "      <th>c_frequency</th>\n",
       "      <th>d_frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>!{2,}_frequency</th>\n",
       "      <th>\\.{3}_frequency</th>\n",
       "      <th>number_lines</th>\n",
       "      <th>number_sentences</th>\n",
       "      <th>number_paragraphs</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>word_per_paragraph</th>\n",
       "      <th>character_per_paragraph</th>\n",
       "      <th>word_per_sentence</th>\n",
       "      <th>ratio_sentencestart_uppercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.133803</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.049296</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>73</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>78</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>68</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14164</th>\n",
       "      <td>124</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>67</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14166 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_characters  ratio_alphabetic  ratio_uppercase  ratio_digit  \\\n",
       "0                   140          0.750000         0.050000     0.021429   \n",
       "1                   141          0.680851         0.042553     0.063830   \n",
       "2                   142          0.781690         0.007042     0.021127   \n",
       "3                   142          0.774648         0.028169     0.021127   \n",
       "4                   123          0.699187         0.008130     0.056911   \n",
       "...                 ...               ...              ...          ...   \n",
       "14161                73          0.712329         0.082192     0.054795   \n",
       "14162                78          0.730769         0.128205     0.038462   \n",
       "14163                68          0.735294         0.000000     0.000000   \n",
       "14164               124          0.790323         0.112903     0.024194   \n",
       "14165                67          0.701493         0.074627     0.059701   \n",
       "\n",
       "       ratio_whitespace  ratio_tabspace  a_frequency  b_frequency  \\\n",
       "0              0.178571        0.014286     0.028571     0.014286   \n",
       "1              0.163121        0.014184     0.028369     0.000000   \n",
       "2              0.133803        0.014085     0.049296     0.007042   \n",
       "3              0.147887        0.014085     0.042254     0.000000   \n",
       "4              0.211382        0.016260     0.048780     0.016260   \n",
       "...                 ...             ...          ...          ...   \n",
       "14161          0.123288        0.027397     0.000000     0.027397   \n",
       "14162          0.128205        0.025641     0.038462     0.025641   \n",
       "14163          0.191176        0.029412     0.029412     0.000000   \n",
       "14164          0.129032        0.016129     0.080645     0.024194   \n",
       "14165          0.134328        0.029851     0.029851     0.029851   \n",
       "\n",
       "       c_frequency  d_frequency  ...  !{2,}_frequency  \\.{3}_frequency  \\\n",
       "0         0.042857     0.028571  ...         0.000000         0.000000   \n",
       "1         0.014184     0.028369  ...         0.000000         0.007092   \n",
       "2         0.042254     0.028169  ...         0.000000         0.000000   \n",
       "3         0.042254     0.021127  ...         0.000000         0.000000   \n",
       "4         0.008130     0.008130  ...         0.000000         0.000000   \n",
       "...            ...          ...  ...              ...              ...   \n",
       "14161     0.027397     0.000000  ...         0.000000         0.000000   \n",
       "14162     0.025641     0.012821  ...         0.000000         0.000000   \n",
       "14163     0.014706     0.014706  ...         0.014706         0.000000   \n",
       "14164     0.040323     0.008065  ...         0.000000         0.000000   \n",
       "14165     0.029851     0.014925  ...         0.000000         0.000000   \n",
       "\n",
       "       number_lines  number_sentences  number_paragraphs  \\\n",
       "0                 1                 2                  1   \n",
       "1                 4                 2                  2   \n",
       "2                 1                 2                  1   \n",
       "3                 1                 2                  1   \n",
       "4                 1                 2                  1   \n",
       "...             ...               ...                ...   \n",
       "14161             1                 2                  1   \n",
       "14162             1                 1                  1   \n",
       "14163             1                 2                  1   \n",
       "14164             1                 1                  1   \n",
       "14165             1                 1                  1   \n",
       "\n",
       "       sentences_per_paragraph  word_per_paragraph  character_per_paragraph  \\\n",
       "0                          2.0                25.0                    140.0   \n",
       "1                          1.5                13.0                     69.5   \n",
       "2                          2.0                22.0                    142.0   \n",
       "3                          2.0                23.0                    142.0   \n",
       "4                          2.0                25.0                    123.0   \n",
       "...                        ...                 ...                      ...   \n",
       "14161                      2.0                10.0                     73.0   \n",
       "14162                      1.0                12.0                     78.0   \n",
       "14163                      2.0                11.0                     68.0   \n",
       "14164                      1.0                17.0                    124.0   \n",
       "14165                      1.0                11.0                     67.0   \n",
       "\n",
       "       word_per_sentence  ratio_sentencestart_uppercase  \n",
       "0                   15.0                            0.5  \n",
       "1                   14.0                            0.5  \n",
       "2                   12.0                            0.0  \n",
       "3                   12.5                            0.5  \n",
       "4                   14.5                            0.5  \n",
       "...                  ...                            ...  \n",
       "14161                6.0                            0.5  \n",
       "14162               14.0                            1.0  \n",
       "14163                8.0                            0.0  \n",
       "14164               18.0                            1.0  \n",
       "14165               11.0                            1.0  \n",
       "\n",
       "[14166 rows x 83 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(data_pan15_training, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Things I want for my business cards but are too expensive: 3 PMS colors.',\n",
       " 'colored edges, soft touch finish, raised spot UV, cut 45°corners.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(data_pan15_training.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 6, 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set((1,1,2,3, 2, 6, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is the first line.', 'This is the first sentence of the second line.', 'This is the second sentence of the second line.', 'This is the first line of the second paragraph.', 'This is the third paragraph.', 'It has one line.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.833333333333333"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"\"\"This is the first line. This is the first sentence of the second line.\n",
    "This is the second sentence of the second line.\n",
    "\n",
    "This is the first line of the second paragraph.\n",
    "\n",
    "This is the third paragraph. It has one line.\"\"\"\n",
    "sent = sent_tokenize(test)\n",
    "print(sent)\n",
    "statistics.mean([len(word_tokenize(sentence)) for sentence in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    [r\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x000002249EE0B040>\n"
     ]
    }
   ],
   "source": [
    "text = 'test + test'\n",
    "print(c.isalpha() for c in text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
