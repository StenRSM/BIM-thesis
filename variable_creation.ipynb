{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the variables used in the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_training = pd.read_csv(r'data\\raw_data\\PAN_15_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_test = pd.read_csv(r'data\\raw_data\\PAN_15_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>02c49444-c779-40aa-8ef6-45455680c150</td>\n",
       "      <td>Was at ITsAP organized workshop for CEOs - won...</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02c49444-c779-40aa-8ef6-45455680c150</td>\n",
       "      <td>Intel Invests $30 Million in Cloud, Embedded R...</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>02c49444-c779-40aa-8ef6-45455680c150</td>\n",
       "      <td>A management principle \"What is rewarded is re...</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02c49444-c779-40aa-8ef6-45455680c150</td>\n",
       "      <td>SETU's new product myDrona - a personalized le...</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>02c49444-c779-40aa-8ef6-45455680c150</td>\n",
       "      <td>Which is a better place for conference banquet...</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13173</th>\n",
       "      <td>13173</td>\n",
       "      <td>fc13c5fe-9028-4625-93a4-3e5c32098d89</td>\n",
       "      <td>@username So COOL!! I like you two together an...</td>\n",
       "      <td>F</td>\n",
       "      <td>50-XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174</th>\n",
       "      <td>13174</td>\n",
       "      <td>fc13c5fe-9028-4625-93a4-3e5c32098d89</td>\n",
       "      <td>@username @username @username @username @usern...</td>\n",
       "      <td>F</td>\n",
       "      <td>50-XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13175</th>\n",
       "      <td>13175</td>\n",
       "      <td>fc13c5fe-9028-4625-93a4-3e5c32098d89</td>\n",
       "      <td>@username @username We have a saying here: if ...</td>\n",
       "      <td>F</td>\n",
       "      <td>50-XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>13176</td>\n",
       "      <td>fc13c5fe-9028-4625-93a4-3e5c32098d89</td>\n",
       "      <td>Had a wish just now and it got fulfilled! YAY!...</td>\n",
       "      <td>F</td>\n",
       "      <td>50-XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13177</th>\n",
       "      <td>13177</td>\n",
       "      <td>fc13c5fe-9028-4625-93a4-3e5c32098d89</td>\n",
       "      <td>@username @username Stick Together!\\t\\t</td>\n",
       "      <td>F</td>\n",
       "      <td>50-XX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13178 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                author  \\\n",
       "0               0  02c49444-c779-40aa-8ef6-45455680c150   \n",
       "1               1  02c49444-c779-40aa-8ef6-45455680c150   \n",
       "2               2  02c49444-c779-40aa-8ef6-45455680c150   \n",
       "3               3  02c49444-c779-40aa-8ef6-45455680c150   \n",
       "4               4  02c49444-c779-40aa-8ef6-45455680c150   \n",
       "...           ...                                   ...   \n",
       "13173       13173  fc13c5fe-9028-4625-93a4-3e5c32098d89   \n",
       "13174       13174  fc13c5fe-9028-4625-93a4-3e5c32098d89   \n",
       "13175       13175  fc13c5fe-9028-4625-93a4-3e5c32098d89   \n",
       "13176       13176  fc13c5fe-9028-4625-93a4-3e5c32098d89   \n",
       "13177       13177  fc13c5fe-9028-4625-93a4-3e5c32098d89   \n",
       "\n",
       "                                                    text gender    age  \n",
       "0      Was at ITsAP organized workshop for CEOs - won...      M  35-49  \n",
       "1      Intel Invests $30 Million in Cloud, Embedded R...      M  35-49  \n",
       "2      A management principle \"What is rewarded is re...      M  35-49  \n",
       "3      SETU's new product myDrona - a personalized le...      M  35-49  \n",
       "4      Which is a better place for conference banquet...      M  35-49  \n",
       "...                                                  ...    ...    ...  \n",
       "13173  @username So COOL!! I like you two together an...      F  50-XX  \n",
       "13174  @username @username @username @username @usern...      F  50-XX  \n",
       "13175  @username @username We have a saying here: if ...      F  50-XX  \n",
       "13176  Had a wish just now and it got fulfilled! YAY!...      F  50-XX  \n",
       "13177            @username @username Stick Together!\\t\\t      F  50-XX  \n",
       "\n",
       "[13178 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pan15_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "\n",
    "\n",
    "# Character-based features\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def alphabetic_ratio(text):\n",
    "    alphabetic = sum(c.isalpha() for c in text)\n",
    "    return alphabetic/len(text)\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    upper = sum(c.isupper() for c in text)\n",
    "    return upper/len(text)\n",
    "\n",
    "def digit_ratio(text):\n",
    "    digit = sum(c.isdigit() for c in text)\n",
    "    return digit/len(text)\n",
    "\n",
    "def whitespace_ratio(text):\n",
    "    whitespace = sum(c.isspace() for c in text)\n",
    "    return whitespace/len(text)\n",
    "\n",
    "def tab_ratio(text):\n",
    "    tabs = text.count('\\t')\n",
    "    return tabs/len(text)\n",
    "\n",
    "def letter_ratio(text, letter):\n",
    "    text = text.lower()\n",
    "    letter_count = text.count(letter)\n",
    "    return letter_count/len(text)\n",
    "\n",
    "def specialcharacter_ratio(text, character):\n",
    "    spec_count = text.count(character)\n",
    "    return spec_count/len(text)\n",
    "\n",
    "# Word-based features\n",
    "def number_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return len(words)\n",
    "\n",
    "def word_length(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length/num_words\n",
    "\n",
    "def vocabulary_richness(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_uniq_words = len(set(words))\n",
    "    return num_uniq_words/num_words\n",
    "\n",
    "def long_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    long_words_list = [word for word in words if len(word) > 6]\n",
    "    return len(long_words_list)/len(words)\n",
    "\n",
    "def short_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    short_words_list = [word for word in words if 1 <= len(word) <= 3]\n",
    "    return len(short_words_list)/len(words)\n",
    "\n",
    "def legomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    return len(legomena)/len(words)\n",
    "\n",
    "def dislegomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    return len(dislegomena)/len(words)\n",
    "\n",
    "def yules_k(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    Vi = FreqDist(freq.values())\n",
    "    K = 10**4 * ((-N + sum(i**2 * Vi[i] for i in Vi))/N**2)\n",
    "    return K\n",
    "\n",
    "def simpson_d(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    if N < 2:\n",
    "        return 0\n",
    "    D = sum(fr * (fr - 1) / (N * (N - 1)) for fr in freq.values())\n",
    "    return D\n",
    "\n",
    "def sichel_s(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    S = len(dislegomena)/len(freq.values())\n",
    "    return S\n",
    "\n",
    "def honores_r(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    V = len(freq.values())\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    R = (100*np.log(N)/(1-(len(legomena)/V)))\n",
    "    return R\n",
    "\n",
    "def entropy(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    E = -sum((fr / N) * np.log(fr/N) for fr in freq.values())\n",
    "    return E\n",
    "\n",
    "# Syntatic features\n",
    "def punctuations_ratio(text, punctuation):\n",
    "    punctuation_list = re.findall(punctuation, text)\n",
    "    return len(punctuation_list)/len(text)\n",
    "\n",
    "# Structural features\n",
    "def lines(text):\n",
    "    return len(text.split('\\n'))\n",
    "\n",
    "def sentences(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "def paragraphs(text):\n",
    "    return len([par for par in text.split('\\n\\n') if par.strip()])\n",
    "\n",
    "def sentence_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(sent_tokenize(par)) for par in pars])\n",
    "\n",
    "def words_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(re.findall(r'\\b\\w+\\b', par)) for par in pars])\n",
    "\n",
    "def chars_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(par) for par in pars])\n",
    "\n",
    "def words_sentences(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return statistics.mean([len(word_tokenize(sentence)) for sentence in sents])\n",
    "\n",
    "def uppercase_start(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return (sum(1 for sentence in sents if sentence[0].isupper()) / len(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataframe, text_column):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Character-based features\n",
    "    features['total_characters'] = dataframe[text_column].apply(character_count)\n",
    "    features['ratio_alphabetic'] = dataframe[text_column].apply(alphabetic_ratio)\n",
    "    features['ratio_uppercase'] = dataframe[text_column].apply(uppercase_ratio)\n",
    "    features['ratio_digit'] = dataframe[text_column].apply(digit_ratio)\n",
    "    features['ratio_whitespace'] = dataframe[text_column].apply(whitespace_ratio)\n",
    "    features['ratio_tabspace'] = dataframe[text_column].apply(tab_ratio)\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    for letter in letters:\n",
    "        features[letter+'_frequency'] = dataframe[text_column].apply(letter_ratio, args=(letter,))\n",
    "    special_characters = ['~', '@', '#', '$', '%', '^', '&', '*', '-', '_', '=', '+', '>', '<', '[', ']', '{', '}', '/', '\\\\', '|']\n",
    "    for character in special_characters:\n",
    "        features[character+'_frequency'] = dataframe[text_column].apply(specialcharacter_ratio, args=(character,))\n",
    "    \n",
    "    # Word-based features\n",
    "    features['total_words'] = dataframe[text_column].apply(number_words)\n",
    "    features['word_length'] = dataframe[text_column].apply(word_length)\n",
    "    features['vocabulary_richness'] = dataframe[text_column].apply(vocabulary_richness)\n",
    "    features['long_words'] = dataframe[text_column].apply(long_words)\n",
    "    features['short_words'] = dataframe[text_column].apply(short_words)\n",
    "    features['hapax_legomena'] = dataframe[text_column].apply(legomena)\n",
    "    features['hapax_dislegomena'] = dataframe[text_column].apply(dislegomena)\n",
    "    features['yules_k'] = dataframe[text_column].apply(yules_k)\n",
    "    features['simpson_d'] = dataframe[text_column].apply(simpson_d)\n",
    "    features['sichel_s'] = dataframe[text_column].apply(sichel_s)\n",
    "    features['honore_r'] = dataframe[text_column].apply(honores_r)\n",
    "    features['entropy'] =  dataframe[text_column].apply(entropy)\n",
    "    # Brunet W?\n",
    "    # word length frequency distribution\n",
    "\n",
    "    \n",
    "    # Syntactic features\n",
    "    punctuations = [r\"â€™\", r\",\", r\"\\.\", r\":\", r\";\", r\"\\?\", r\"\\?{2,}\", r\"!\", r\"!{2,}\", r\"\\.{3}\"]\n",
    "    for punctuation in punctuations:\n",
    "        features[punctuation+\"_frequency\"] = dataframe[text_column].apply(punctuations_ratio, args=(punctuation,))\n",
    "\n",
    "    # Structural features\n",
    "    features['number_lines'] = dataframe[text_column].apply(lines)\n",
    "    features['number_sentences'] = dataframe[text_column].apply(sentences)\n",
    "    features['number_paragraphs'] = dataframe[text_column].apply(paragraphs)\n",
    "    features['sentences_per_paragraph'] = dataframe[text_column].apply(sentence_paragraph)\n",
    "    features['word_per_paragraph'] = dataframe[text_column].apply(words_paragraph)\n",
    "    features['character_per_paragraph'] = dataframe[text_column].apply(chars_paragraph)\n",
    "    features['word_per_sentence'] = dataframe[text_column].apply(words_sentences)\n",
    "    features['ratio_sentencestart_uppercase'] = dataframe[text_column].apply(uppercase_start)\n",
    "    features['gender'] = dataframe['gender']\n",
    "    features['age'] = dataframe['age']\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_train = extract_features(data_pan15_training, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_test = extract_features(data_pan15_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_characters</th>\n",
       "      <th>ratio_alphabetic</th>\n",
       "      <th>ratio_uppercase</th>\n",
       "      <th>ratio_digit</th>\n",
       "      <th>ratio_whitespace</th>\n",
       "      <th>ratio_tabspace</th>\n",
       "      <th>a_frequency</th>\n",
       "      <th>b_frequency</th>\n",
       "      <th>c_frequency</th>\n",
       "      <th>d_frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>!{2,}_frequency</th>\n",
       "      <th>\\.{3}_frequency</th>\n",
       "      <th>number_lines</th>\n",
       "      <th>number_sentences</th>\n",
       "      <th>number_paragraphs</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>word_per_paragraph</th>\n",
       "      <th>character_per_paragraph</th>\n",
       "      <th>word_per_sentence</th>\n",
       "      <th>ratio_sentencestart_uppercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "      <td>13178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79.245409</td>\n",
       "      <td>0.728750</td>\n",
       "      <td>0.073417</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>0.169534</td>\n",
       "      <td>0.034626</td>\n",
       "      <td>0.057177</td>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.023249</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>1.062225</td>\n",
       "      <td>1.647063</td>\n",
       "      <td>1.007133</td>\n",
       "      <td>1.640967</td>\n",
       "      <td>13.262603</td>\n",
       "      <td>78.897936</td>\n",
       "      <td>11.638788</td>\n",
       "      <td>0.548083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.136378</td>\n",
       "      <td>0.060088</td>\n",
       "      <td>0.090831</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.038658</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>0.029597</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.358864</td>\n",
       "      <td>1.002671</td>\n",
       "      <td>0.097526</td>\n",
       "      <td>0.992888</td>\n",
       "      <td>6.538972</td>\n",
       "      <td>37.094613</td>\n",
       "      <td>6.480261</td>\n",
       "      <td>0.436502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020270</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141509</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>111.000000</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_characters  ratio_alphabetic  ratio_uppercase   ratio_digit  \\\n",
       "count      13178.000000      13178.000000     13178.000000  13178.000000   \n",
       "mean          79.245409          0.728750         0.073417      0.014592   \n",
       "std           37.136378          0.060088         0.090831      0.023656   \n",
       "min            5.000000          0.210526         0.000000      0.000000   \n",
       "25%           48.000000          0.702703         0.024691      0.000000   \n",
       "50%           76.000000          0.739130         0.052632      0.000000   \n",
       "75%          111.000000          0.768116         0.097222      0.022222   \n",
       "max          194.000000          0.948052         0.903226      0.317073   \n",
       "\n",
       "       ratio_whitespace  ratio_tabspace   a_frequency   b_frequency  \\\n",
       "count      13178.000000    13178.000000  13178.000000  13178.000000   \n",
       "mean           0.169534        0.034626      0.057177      0.012065   \n",
       "std            0.038658        0.025489      0.029597      0.014777   \n",
       "min            0.020270        0.010309      0.000000      0.000000   \n",
       "25%            0.141509        0.018018      0.037879      0.000000   \n",
       "50%            0.164948        0.026316      0.054795      0.008475   \n",
       "75%            0.195122        0.041667      0.074074      0.019231   \n",
       "max            0.592593        0.400000      0.441176      0.200000   \n",
       "\n",
       "        c_frequency   d_frequency  ...  !{2,}_frequency  \\.{3}_frequency  \\\n",
       "count  13178.000000  13178.000000  ...     13178.000000     13178.000000   \n",
       "mean       0.023249      0.020996  ...         0.000569         0.001013   \n",
       "std        0.019565      0.019478  ...         0.003905         0.004906   \n",
       "min        0.000000      0.000000  ...         0.000000         0.000000   \n",
       "25%        0.008197      0.000000  ...         0.000000         0.000000   \n",
       "50%        0.021505      0.018182  ...         0.000000         0.000000   \n",
       "75%        0.034884      0.031250  ...         0.000000         0.000000   \n",
       "max        0.181818      0.372549  ...         0.090909         0.117647   \n",
       "\n",
       "       number_lines  number_sentences  number_paragraphs  \\\n",
       "count  13178.000000      13178.000000       13178.000000   \n",
       "mean       1.062225          1.647063           1.007133   \n",
       "std        0.358864          1.002671           0.097526   \n",
       "min        1.000000          1.000000           1.000000   \n",
       "25%        1.000000          1.000000           1.000000   \n",
       "50%        1.000000          1.000000           1.000000   \n",
       "75%        1.000000          2.000000           1.000000   \n",
       "max        8.000000         11.000000           4.000000   \n",
       "\n",
       "       sentences_per_paragraph  word_per_paragraph  character_per_paragraph  \\\n",
       "count             13178.000000        13178.000000             13178.000000   \n",
       "mean                  1.640967           13.262603                78.897936   \n",
       "std                   0.992888            6.538972                37.094613   \n",
       "min                   1.000000            1.000000                 5.000000   \n",
       "25%                   1.000000            8.000000                47.000000   \n",
       "50%                   1.000000           13.000000                76.000000   \n",
       "75%                   2.000000           18.000000               111.000000   \n",
       "max                  11.000000           34.000000               194.000000   \n",
       "\n",
       "       word_per_sentence  ratio_sentencestart_uppercase  \n",
       "count       13178.000000                   13178.000000  \n",
       "mean           11.638788                       0.548083  \n",
       "std             6.480261                       0.436502  \n",
       "min             1.000000                       0.000000  \n",
       "25%             7.000000                       0.000000  \n",
       "50%            10.000000                       0.500000  \n",
       "75%            15.000000                       1.000000  \n",
       "max            44.333333                       1.000000  \n",
       "\n",
       "[8 rows x 83 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pan15_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_test.to_csv(r'data\\pan15_features_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
